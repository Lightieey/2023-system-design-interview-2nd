## 처리율 제한 장치의 설계

네트워크 시스템에서 처리율 제한 장치(rate limiter)는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치다.
HTTP를 예로 들면 이 장치는 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한한다.
API 요청 횟수가 제한 장치에 정의된 임계치(threshold)를 넘어서면 추가로 도달한 모든 호출은 처리가 중단(blocK)된다.

### 몇가지 사례

1. 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
2. 같은 IP주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
3. 같은 디바이스로는 주당 5회 이상 리워드를 요청할 수 없다.

### API에 처리율 제한 장치를 두면 좋은 점

1. Dos(Denial of Service) - 공격에 의한 자원 고갈(resource starvation)을 방지 할 수 있다.

- EX) 트위터는 3시간 동안 300개의 트윗만 올릴 수 있도록 제한.
- EX) 구글 독스 API는 사용자당 분당 300회의 read만 허용한다.

처리율 제한 장치는 추가 요청에 대해서는 처리를 중단함으로써 Dos 공격을 방지한다.

2. 비용 절감

- 추가 요청에 대한 처리를 제한하면 서버를 많이 두지 않아도 되고, 우선 순위가 높은 API에 대해 더 많은 자원을 할당할 수 있다.
- 더불어 제3자 API에 사용료를 지불하고 있는 회사들에게는 해당 사안이 매우 중요하다.

3. 서부 과부하를 막는다.

- 봇에서 오는 트래픽이나 사용자의 잘못된 이용 패턴으로 유발된 트래픽을 걸러낼 수 있다.

### 처리율 제한 장치는 어디에 둘 것인가?

- 직관적으로 보면 클라이언트 측에 둘 수도 있고, 서버측에 둘 수도 있다.
- 하지만 일반적으로 클라측은 처리율 제한을 안정적으로 걸 수 있는 장소가 되지 못한다.
- 이유는 클라 요청은 쉽게 위변조가 가능하다.
- 더불어 모든 클라이언트 구현을 통제하는 것도 어려울 수 있다.
- API 서버측과 함께 둘 수도 있음 그러나..
- 가장 이상적인 방법은 처리율 제한 장치를 API서버에 함께 두는 것 보다는,
- "처리율 제한 미들웨어"를 만들어 해당 미들웨어로 하여금 API 서버로 가는 요청을 통제하도록 하는 것이다.
- 클라우드 MSA의 경우 처리율 제한 장치는 보통 API 게이트웨이라 불리는 컴포넌트에 구현된다.
- API 게이트웨이는 처리율 제한, SSL제한, 사용자 인증 , IP허용 목록 관리등을 지원하는 위탁 관리형 서비스이다.

### 개략적인 아키텍처

- 처리율 제한 알고리즘의 기본 아이디어는 단순하다.
- 얼마나 많은 요청이 접수되었는지를 추적할 수 있는 카운터를 추적 대상별로 두고 사용자별, IP 주소별, 아니면 API 엔드포인트나 서비스 단위별로 제한을 둘지 결정하면 되는 것이다.
- 그러면 이 카운터는 어디다 둘 것인가?
- DB는 기본적으로 디스크 접근 때문에 느리니까 X
- 메모리상에서 동작하는 캐시가 바람직 -> 빠른데다 시간에 기반한 만료 정책 지원
- 레디스 !
- INCR과 EXPIRE 두 가지 명령어 지원

<b> INCR : 메모리에 저장된 카운터의 값을 1만큼 증가시킨다. </b>
<b> EXPIRE : 카운터에 타임아웃 값을 설정한다. 설정된 값이 지나면 카운터는 자동으로 삭제된다. </b>

동작 원리는 다음과 같다.

- 클라가 처리율 제한 미들웨어에게 요청을 전송
- 처리율 제한 미들웨어는 레디스의 지정 버킷에서 카운터를 가져와서 한도에 도달 유무 검사
- 한도 도달시 요청 거부
- 한도에 도달하지 않았다면 요청은 API 서버로 전달
- 한편 미들웨어는 카운터의 값을 증가시킨 후 다시 레디스에 저장

### 상세 설계

다음과 같은 물음이 떠오를 수 있다.

- 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?
- 처리가 제한된 요청들을 어떻게 처리하는가?

<b> 처리율 제한 규칙 </b>

리프트(Lyft)는 처리율 제한에 오픈 소스를 사용하고 있다. 이 컴포넌트를 들여다보고, 어떤 처리율 제한 규칙이 사용되고 있는지 살펴보자.

```
domain: messaging
descriptors:
    - key: message_type
      Value: marketing
      rate_limit :
          unit: day
          request_per_unit : 5
```

위의 예시는 시스템이 처리할 수 있는 마케팅 메시지의 최대치를 하루 5개로 제한하고 있다.

또 다른 규칙을 살펴보자.

```
domain: auth
descriptors:
   - key: auth_type
     Value: login
     rate_limit:
         unit: minute
         requests_per_unit : 5
```

이 규칙은 클라이언트가 분당 5회 이상 로그인 할 수 없도록 제한하고 있다. 이런 규칙들은 보통 설정 파일(configuration file) 형태로 디스크에 저장된다.

### 처리율 제한 장치가 사용하는 HTTP 헤더

클라는 자기 요청이 처리율 제한에 걸리고 있는지 어떻게 감지 하나?
자기 요청이 처리율 제한에 걸리기까지 얼마나 많은 요청을 보낼 수 있는지 어떻게 알 수 있나?

답은 HTTP 응답 헤더에 있다.
처리율 제한 장치는 다음 HTTP 헤더를 클라이언트에게 보낸다.

- X-Ratelimit-Remaining : 윈도 내에 남은 처리 가능 요청의 수.
- X-Ratelimit-Limit: 매 윈도마다 클라가 전송할 수 있는 요청의 수.
- X-Ratelimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림.

### 상세 설계

- 처리율 제한 규칙은 "디스크"에 보관
- 작업 프로세스(worker)는 수시로 규칙을 디스크에서 읽어 캐시에 저장.
- 클라가 요청을 서버에 보내면 요청은 먼저 처리율 제한 미들웨어에 도달.
- 처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져옴.
- 아울러 카운터 및 마지막 요청의 타임스탬프를 레디스 캐시에서 가져옴.
- 가져온 값들에 근거해 미들웨어는 다음과 같은 결정을 내림
  -> 해당 요청이 처리율 제한에 걸리지 않으면 API 서버로 전송
  -> 해당 요청이 처리율 제한에 걸렸으면 429 too many requests 에러 클라에게 전송
  -> 한편, 해당 요청은 그대로 버릴 수도, 메시지 큐에 보관 할 수도 있다.

### 분산 환경에서의 처리율 제한 장치의 구현

단일 서버 지원하는 처리율 제한 장치를 구현하는 것은 어렵지 않다.
하지만 여러 대의 서버와 병렬 스레드를 지원하도록 시스템을 확장하는 것은 또 다른 문제다.

다음 두 가지 어려운 문제를 풀어야 한다.
<b> 경쟁 조건(race condition) </b>
<b> 동기화(syncronization) </b>

#### 경쟁 조건

앞서 살펴본 대로, 처리율 제한 장치는 대략 다음과 같이 동작한다.

- 레디스에서 카운터의 값을 읽는다 (counter)
- counter + 1의 값이 임계치를 넘는지 확인한다.
- 넘지 않으면 레디스에 보관된 counter의 값을 1만큼 증가시킨다.

하지만, 병행성이 심한 환경에서는 경쟁 조건 이슈가 발생 가능 !

경쟁 조건 문제를 해결하는 가장 널리 알려진 해결책 -> 락 (LOCK)
하지만 락은 시스템 성능 저하를 불러 일으키는 문제가 있다.
락 대신 쓸 수 있는 해결책이 두가지 존재 !
하나는 루아 스크립트(Lua Script), 다른 하나는 정렬 집합(Sorted Set)이라 불리는 레디스 자료구조를 쓰는 것이다.

#### 동기화 이슈

수백만 사용자를 지원하려면 한 대의 처리율 제한 장치 서버로는 충분치 않다.
그래서 처리율 제한 장치 서버를 여러 대 두게 되면 동기화가 필요해진다.
특정 요청을 특정 서버에서만 기억하고 있다면 다른 서버는 특정 요청에 대한 기억이 없다.
웹 계층은 무상태성 이므로.
따라서 동기화를 수행하지 않으면 서로 다른 제한율 처리 장치 서버는 서로에 대한 상황을 몰라 처리율 제한을 올바르게 수행할 수 없다.

따라서 이와 같은 해결책은 역시 레디스!

중앙 집중형 데이터 저장소를 사용해 한 곳에서 해당 카운터의 정보를 처리하는 것이다.

## 추가 공부 - Lua Script, 정렬 집합 자료구조

Redis Lua 스크립팅을 사용시 레디스 내에서 Lua 스크립트 작성이 가능해짐. Lua는 다른 응용 프로그램에 포함되도록 설계된 경량의 고급 프로그래밍 언어.

Redis Lua 스크립팅은 일반적으로 Redis의 기본 제공 명령으로 쉽게 수행할 수 없는 복잡한 데이터 조작 작업을 수행하는 데 사용됩니다. 예를 들어 Lua 스크립팅을 사용하여 사용자 정의 집계 함수를 구현하거나 그래프 계산을 수행하거나 사용자 정의 검색 알고리즘을 구현할 수 있습니다.

https://dev.gmarket.com/69

### Redis Lua Script를 이용해서 API Rate Limiter개발

### 1. API Rate Limiter 도입 필요성

요구 사항 : "1분당 100건의 상품만 등록할 수 있고 상품 엑셀 등록 서비스로는 최대 500개까지 상품을 한 번에 등록시킬 수 있다"라는 요구사항을 처리하기 위해서 Redis를 이용해서 API 호출 수를 기록하고 API 호출 수가 100 미만일 경우에만 상품 등록 API를 호출하도록 해야 합니다.

### 2. API Rate Limiter 적용

... 생략

### 3. API Rate Limiter에서 발생하는 문제

- 코드 실행시 실제로 1분당 100건의 호출 수가 지켜지지 않음
- 일부 호출은 1분당 100건을 초과했음에도 불구하고 상폼등록 API에 유입됨
- 이유는 단일 컨슈머로 처리하는 것이 아닌 (Kafka) 16개의 컨슈머로 상품등록을 처리하기에 race condition 발생.

- 단일 컨슈머로 처리한다면 아무 문제 없이 반드시 1분에 100개의 호출을 처리하지만 아래 그림처럼 4개의 컨슈머가 동시에 API 호출 수가 99인 상황에서 조회하면 4개의 컨슈머는 현재 API 호출 수가 99이므로 마지막으로 API호출이 가능하다고 판단하고 API를 호출
- 셀러별 API 호출 수를 조회하고 100보다 작은 값인지 확인 후 1 증가시켜 주는 로직이 atomic 하지 않아서 race condition이 발생 !!!

- Redis는 싱글 스레드와 이벤트루프 기반의 비동기방식으로 동작하기 때문에 한 번에 하나의 요청 처리.
- 하지만 컨슈머 코드에선 처리한 호출수 제한 로직은 atomic 연산 X
- 1번 과정에서 동시에 여러 컨슈머가 같은 값을 읽어가서 발생하는 문제.

```
1. 현재 셀러의 API 호출 수를 get 해온다. (4개의 컨슈머가 1번에 동시에 접근한다면 모두가 99라는 값을 읽어가는 문제 발생)
2. API 호출수가 max값보다 작으면 API 호출 수를 1 증가시킨다
3. TTL을 설정한다.
```

### 4. Lua script를 실행시켜 atomic연산을 보장하도록 개선

- Redis는 2.6 버전부터 내장된 Lua Script Engine을 이용하여 서버에서 Lua Script 사용 가능
- 해당 기능 이용하여 API Rate Limiter에서 발생하는 race condition 문제 해결 가능
- Lua Script에 작성한 로직을 실행하면 해당 연산이 Redis 서버에서 원자적(atomic)으로 처리되기 때문
- 컨슈머에서 API 호출 수를 사용할 때 race condition이 발생한다는 것을 확인했는데 이를 해결하기 위해서는 Lua script를 작성하고 Lua script을 실행시켜서 atomic연산이 보장되도록 개선이 필요

<br>

- 동시에 4개의 컨슈머가 Lua Script를 실행시킨다면 레디스 서버에서 순차적으로 atomic연산으로 실행시키므로 가장 먼저 도착한 컨슈머의 Lua Script가 API 호출 수를 100으로 증가(1분당 100건의 상품만 등록시키는 요구조건 만족)시키기 때문에 다음 Lua script에서는 API 호출수가 100 임을 확인하고 더 이상 API 호출 수를 증가시키지 않고 그대로 현재 값을 반환.

#### 주의사항

- Redis에서 Lua Script를 실행시킬 경우 해당 스크립트는 반드시 짧게 끝나는 로직으로 작성
- 만약, 처리시간이 오래 걸리는 로직이 들어가면 싱글스레드 기반의 레디스는 해당 스크립트를 실행하는 동안 다른 요청을 처리하지 못하는 일이 발생

< Lua script에는 조회해야 하는 셀러의 API 호출 수를 조회하고 최댓값에 도달했는지에 따라서 1을 증가시키거나 바로 0을 리턴하는 코드 >

```java
local key = KEYS[1] -- unique key
local limitCount = tonumber (ARGV[1]) -- limit size
local limitTime = tonumber (ARGV[2]) --  limiting time
local current = tonumber(redis.call('get', key) or '0')

if current + 1 > limitCount then -- 분당호출수 초과시 0 return
    return 0

else
    redis.call('INCRBY', key,'1')
    redis.call('expire', key,limitTime)
    return current + 1
end
```

해당 코드는 atomic 하게 실행되므로 여러 컨슈머가 동시에 실행했더라도 레디스 서버에서 순차적으로 차례차례 실행시키므로 동시성 문제가 발생하지 않음.

---

### [코드 해석]

local key = KEYS[1] - KEYS 배열에서 첫 번째 요소를 가져와 key 변수에 할당 -> EX) "user_id : 123"

local limitCount = tonumber(ARGV[1]) - ARGV 배열에서 첫 번째 요소를 가져와 limitCount 변수에 할당합니다. 이 변수는 시간당 허용되는 최대 작업 수 -> 100개

local limitTime = tonumber(ARGV[2]) - ARGV 배열에서 두 번째 요소를 가져와 limitTime 변수에 할당합니다. 이 변수는 제한 시간(초) -> 1분

```java
ARGB : 특정 배열

- EX) EVAL "return tonumber(ARGV[1]) + tonumber(ARGV[2])" 2 10 20
  -> 30 반환
```

redis.call('get', key)를 사용하여 Redis에서 key에 해당하는 값을 가져옴. get으로 가져온 값이 없다면, "nil" 즉, 0으로 대체. 해당 값을 current(현재 작업 수)변수에 할당.

- 위에서 user_id가 123인 유저의 현재 요청 횟수 (current) 확인.

if current + 1 > limitCount then - 현재 작업 수에 1을 더한 값이 limitCount(100)를 초과하는지 확인합니다. 즉, 시간당 허용되는 최대 작업 수를 초과하는 경우입니다.

return 0 - 작업 수가 제한을 초과하면 0을 반환하고 더 이상의 작업을 허용하지 않습니다.

else - 그렇지 않은 경우(제한을 초과하지 않은 경우)에는 다음 작업을 수행합니다.

redis.call('INCRBY', key, '1') - Redis에서 key에 대한 값을 1 증가시킵니다. 이것은 현재 작업 수를 업데이트하는 역할을 합니다.

redis.call('expire', key, limitTime) - key의 만료 시간을 limitTime(1분)으로 설정합니다. 이것은 제한 시간 동안 작업 수를 저장하고 나중에 다시 초기화하는 데 사용됩니다.

return current + 1 - 업데이트된 작업 수를 반환합니다. 이것은 현재 요청을 처리하는 데 사용됩니다.

### 추가공부 2 - 레디스 ( 정렬 집합(Sorted Set) 자료구조 )

#### Sorted Set 이란?

<img src= https://velog.velcdn.com/images/hgs-study/post/2e3811e7-7e8c-4df9-aa15-961d8a03bd46/image.png>

- Sorted Sets는 Key하나에 여러개의 Score와 Value로 구성하는 자료구조.
- Value는 score로 sort되며 중복되지 않음.
- score가 같으면 "value"로 sort.
- Sorted Sets에서는 집합이라는 의미에서 value를 'member'라고 지칭
- Sorted Sets은 주로 sort가 필요한 곳에 사용.

간단히 정리하면, 한 Key에 여러 value와 score를 가지고 있으며 중복되지 않는 value score순으로 데이터 정렬!

### 기프티콘 선착순 이벤트 구조 - Sorted Set을 활용한 선착순 이벤트

<img src =https://velog.velcdn.com/images/hgs-study/post/9add5f28-20d4-4d36-b72e-2413bf323955/image.png>

- Sorted Set Key에는 GIFTICON_EVENT 설정.
- Value에는 사용자명 설정 (영숙,영희,철이,말숙) -> 이름으로 설정했지만 동명이인이 있을 수 있으므로 user_id와 같은 고유한 값 사용 가능,
- score에는 참여한 사람들을 순서대로 정렬 하기 위해, 이벤트를 참여한 시간을 유닉스타임(m/s) 값으로 설정.

#### 어플리케이션 구성

<b> 기프티콘 100개 선착순 이벤트 시 1000명이 요청했을 경우 </b>

<img src= https://velog.velcdn.com/images/hgs-study/post/ec1bf878-c934-499a-8f3f-ab7a8f93bfa1/image.png>

1. 100명의 유저가 기프티콘 달라고 요청
2. 100명의 유저는 대기열에 쌓임
3. 1초마다 동기화 돼어 기프티콘 발급 성공 또는 실패 로직 수행
4. 성공일 경우 & 100명이 넘지 않았으면 1000명의 유저 중 먼저 들어온 순서대로 20명씩(고정값X) 기프티콘 발급
5. 처음 20명 안에 못들었을 경우 다음 대기열로 돌아가서 남은 대기열 순번 표출.
6. 해당 과정을 반복하면서 100명에게만 기프티콘 부여.

- 20개씩 나눠서 발급 이유 : DB 부하 감소 위함

### 치킨 기프티콘 선착순 이벤트 실습

ref : https://github.com/hgs-study/redis-sorted-set-practice
