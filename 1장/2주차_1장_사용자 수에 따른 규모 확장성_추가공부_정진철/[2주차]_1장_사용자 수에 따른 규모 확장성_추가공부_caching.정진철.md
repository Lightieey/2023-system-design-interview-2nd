## Reveal2021 - 쿠팡의 대규모 트래픽을 다루는 백앤드 전략 요약

ref : https://www.youtube.com/watch?v=qzHjK1-07fI

### 1. What circumstances : E - commerce Data

- Aggregate from Multiple Domain Data
- Change Frequently and Instantly
- The more Displayed, The more Sales

<img src="https://velog.velcdn.com/images/bik1111/post/85bbc084-2bdd-4b35-804b-9416ef9b8165/image.png" width="400px;" alt="">

위의 이미지에서는 한 화면 단에 카탈로그, 가격, 도착예정일, 리뷰 수, 평균평점 등 복합적인 데이터가 한 곳에 자리한다.
해당 이미지 기준으로 4300가량의 리뷰가 있으니 별점 평균을 매길때도 4300개의 모든 평점을 다 더하고 해당 갯수로 나눠줘야 평균 별점을 알 수 있다. 4300개의 데이터를 읽는 것 자체도 버거운데 평균 연산까지 들어가니 부하 요소가 커진다.

<img src = "https://velog.velcdn.com/images/bik1111/post/d8a8787e-2be1-472a-a39f-b1ccd3518482/image.png" width="400px;" alt="">

따라서, 유저 수를 약 100만명으로 추정하고 100만명 모두에게 각각의 도메인에서 가져온 데이터를 뿌려야 한다면 각각의 백엔드 서버가 모두 고가용성이 보장되어야 하며 공통으로 적용되는 비지니스의 중복 코드가 상당히 많이 발생할 것.

### 그러므로 모든 페이지에서 "공통" 으로 사용되는 데이터와 비지니스 로직을 처리하는 마이크로 서비스가 필요한 이유가 부상.

결론적으로 쿠팡 코어 서빙 플랫폼은 모든 페이지에서 고가용성, 저지연 데이터를 제공하는 것이 목표 !

<img src="https://velog.velcdn.com/images/bik1111/post/5ef387c3-1437-48d7-88a0-2757ee269ab5/image.png" width=400px; alt="">

그래서 위의 사진과 같이 모든 도메인에서 산출되는 데이터를 한 곳으로 집결시키는 일종의 코어 서빙 레이어 구축

코어 서빙 레이어는 쿠팡에서 화면 구성에 필요로 하는 모든 데이터와 비지니스 로직을 제공한다. 그러한 데이터들은 <b> Common Storage </b> 로부터 받아서 제공한다.

코어 서빙 레이어가 각각의 도메인을 일일이 예민하게 쳐다보고 있는 것이 아닌, 각각의 도메인의 데이터 변경 시 큐에 전송하고 해당 데이터를 NoSQL 데이터베이스에 저장한다.

하나의 상품정보가 존재한다면 해당 상품을 이루는 데이터 요소요소들이 각기 다른 도메인에 의해 채워진다.

아래와 같은 비정규형 테이블에 모든 데이터가 저장됨.

<img src = "https://velog.velcdn.com/images/bik1111/post/3ba66b61-f8c9-415e-9b18-f5440b222cb6/image.png" width=400px; alt="">

위의 이미지와 같이 카탈로그 팀에서는 이미지와 title을 채우고 Pricing 팀에서는 Price를 채우는 형식이다.

이렇게 하는 이유는, Read - Throughput 때문이다. NoSQL 구조를 사용함으로써 트랜잭션 없이 언젠가는 반영될 Eventual Consistency Model을 사용한다. 즉, 한 번의 read로 모든 도메인의 데이터 수취가 가능해진다.

## Cache Layer

<img src= "https://velog.velcdn.com/images/bik1111/post/799fa462-fe2f-4c33-aa00-a04b27b0ae1a/image.png" width=400px; alt="">

Unified된 데이터 스토지지 (중앙 집중형 방식)를 통하여 여러 도메인으로 뻗칠 수 있는 I/O 수행을 줄여 서버 부하를 감소시키고 Common Storage로 Read - Throughput을 향상시켰지만 더 많은 데이터를 처리하기 위해 Cache Layer 따로 생성.

Common Storage는 persistent한 성격이 강하다면 Cache Layer는 높은 Throughput, Low Latency 측면에 더 집중

고성능 캐시 레이어를 통해서 10배 높은 Throughput과 지연은 1/3 수준으로 줄임.

다만, 캐시 레이어는 Common Storage에 반영된 데이터가 정작 캐싱되지 않는 주의점이 존재한다.

예를들어 타 도메인에서 특정 상품의 가격을 변경해 스토리지에 저장은 했지만 캐시에는 반영되지 않는 것이다.

<img src= "https://velog.velcdn.com/images/bik1111/post/6f0f63e9-b2e0-41fc-a0f0-ad79b1f909dc/image.png" width=400px; alt="">

따라서 이러한 문제를 해결하기 위해서 Cache Invalidator 도입.

데이터가 변경될 때 마다 해당 데이터들은 Notification Queue로 보내지고 이 시그널들을 활용해 캐시에 있는 데이터가 최신의 상황인지 확인하고 그렇지 않다면 최신 상태의 데이터로 변화시킨다.

이러한 메커니즘을 통해 Common Serving Layer에서 제공되는 99.9퍼센트의 데이터는 스토리지와 일치하는 최신의 데이터로 서빙됨.

분 단위로 수행하는 Cache Invalidation을 통해 정확성을 매우 높인다.

#### 하지만, 가격, 배송장소, 재고와 같이 "초"단위로 변경되는 데이터는 어떻게 처리될까?

<img src="https://velog.velcdn.com/images/bik1111/post/678dbe74-639e-458a-aec4-050e6492d772/image.png" width=400px; alt="">

가격이나 할인정보는 고객경험에 중대한 영향을 끼치는 요소들이다. 따라서 시차가 발생된 데이터 제공 시 고객경험 수준이 떨어지고 회사에도 손헤 발생.

특히 쿠팡은 로켓배송 상품은 실제로 배송되기 때문에 각 지역별 재고와 배송처리 능력에 따라 상품의 배송시간을 변경해야 할 수도 혹은 품절 시켜야 하는 상황이 발생한다.

이것이 <b>RealTime Data Streaming</b> 도입의 이유다.

RealTime Data Streaming은 다른 도메인에서 변겨된 데이터를 큐에서 읽고 별도의 캐시에 바로 적용한다.
Common Serving Layer는 Cache와 RealTime 캐시를 동시에 읽어 보다 최신의 데이터를 해당 데이터로 서빙할 수 있게끔 설계한다.

하지만 이러한 데이터를 지속적으로 읽어낼 수 있는 가용성이 특성을 빠뜨릴 수 없는데,

가용성이란 고객 경험에 직접적으로 연결되는 장애를 최소화 하는 것이다. 예를들어 RealTime Cache에 장애가 발생하는 경우 페이지 자체를 서빙하지 못하는 것 보다는 최신의 데이터를 제공하지는 못하더라도 특정한 페이지를 제공해주는 것이 더 낫다는 것이다.

이러한 목표를 달성하기 위해서 코어 서빙 레이어에서는 모든 I/O가 일어나는 곳에서 장애가 발생할 때 해당 장애를 격리시켜 Cascading 되지 않도록 해야한다.

그래서 코어 서빙 레이어는 Circuit Breaker라는 기술을 통해 해당 컴포넌트의 장애를 고립시키고 필요시 수동으로 해당 컴포넌트로 가는 I/O 들을 끌 수 있도록 설계하였다.

<img src="https://velog.velcdn.com/images/bik1111/post/95f9aa49-e07a-4185-8938-8e36fc48a09d/image.png" width=400px; alt="">

#### 가용성 측면에서 또 다뤄야 할 중요한 개념 : CSP

### Critical Serving Path

쿠팡에는 굉장히 많은 페이지가 존재하며 그 중 특히 고객경험에 중대한 영향을 끼치는 페이지들이 존재한다.(홈, 검색 페이지, 주문 페이지 등)

따라서 중요도가 높은 페이지만을 다루는 클러스터가 존재 하며 이를 CSP Cluster라고 칭한다.

그리고 그 외의 페이지들을 모아놓은 클러스터들을 NCSP Cluster 라고 한다.

이렇게 분리한 이유는 서로의 독립적인 클러스터는 서로에게 영향을 끼치지 않기 때문이다.

NCSP 클러스터의 캐시가 문제가 일어나도 CSP Cluster에게 문제가 전가되지 않음.

또한 CSP 클러스터에서 문제가 일어나도 추가적인 배포 없이도 동적으로 CSP에 해당하는 페이지가 NCSP Cluster를 바라보게 할 수 도 있다.

<img src= "https://velog.velcdn.com/images/bik1111/post/f346fa61-8b75-4bf6-a12a-17d21b359a2f/image.png" width=400px; alt="">

코어 서빙 레이어에는 상품 정보를 제공하는 도메인 뿐만 아니라 위 그림과 같은 도메인들 역시 존재한다. (고가용성과 저지연이 요구되는 도메인)

만약 각각의 도메인이 구조는 같음에도 불구하고 다른 코드 베이스를 적용한다면 앞선 전략을 수행하기 위한 중복 코드가 증가할 것이고 이는 관리의 어려움으로 직결될 것이다.

따라서 이러한 로직들을 쉽게 구성하기 위해 코어 서빙 레이어 자체를 쉽게 만들어야함.

코어 서빙 레이어를 쉽게 만들기 위해 코어 서빙 레이어 <b> "템플릿" </b> 생성

코어 서빙 레이어 템플릿은 기본적인 핵심 로직을 공유하고 Configuration에 의해 동작이 변경되는 Configuration as Code를 지향한다.

바라봐야 하는 Common Storage주소, 캐시 주소, 리얼 타임 캐시의 주소와 추가적으로 Configuration만 변경하면 새로운 도메인의 코어 서빙 레이어가 생성된다.

<img src="https://velog.velcdn.com/images/bik1111/post/45020102-193d-4c83-92cb-2c98a18dc24f/image.png" width=400px; alt="">

<img src="https://velog.velcdn.com/images/bik1111/post/126b6cdf-2e71-4f91-b23e-83988279ae20/image.png" width=400px; alt="">

### 코어 서빙 레이어의 기술적 어려움 & 개선하기 위한 노력

어려움 1. Availability : 하드웨어, 소프트웨어 문제
어려움 2. Througput : 서버의 처리량을 넘어서는 급격한 사용자 유입

Availability에 영향을 가장 많이 끼친건 캐시 레이어이다. 높은 처리량과 실시간 데이터 반영을 위해 2개의 캐시 클러스터를 사용함.

트래픽이 많은 만큼 한 캐시 클러스터 당 노드 수는 60-100개로 구성.

분당 억대의 트래픽을 처리하며 전체 트래픽 중 캐시와 데이터 스토리지 처리량을 비교해보면 95% 이상을 캐시에서 처리.

캐시 클러스터의 이용 빈도가 높은 만큼 캐리 클러스터의 Availbility가 전체 플랫폼 Availabilty에 많은 영향을 끼친다.

<img src="https://velog.velcdn.com/images/bik1111/post/368d17c0-8fc2-440a-b45e-32583a0b5e6e/image.png" width=400px; alt="">

한 클러스터 당 포함되는 노드의 수가 많다보니 개별 노드들이 다운되는 현상이 자주 발생한다.

특정 노드의 다운은 해당 노드들만의 문제이므로 Circuit Breaker만으로는 해결하기 어렵다.

캐시 클러스터는 빠르게 실패 노드들을 찾아서 클러스터 Topology를 변경하지만 이러한 도구 작업에도 시간이 소요되며 그 시간에 처리되지 못하는 요청들은 타임아웃 혹은 내부 큐에 쌓이게 된다.

또한 클러스터 Topology 변경이 실제 사용되는 TCP연결과 일치 하지 않아 다운된 노드로 트래픽이 유입되는 현상 역시 발생.

시스템 안정성을 높이기 위해 다운된 노드로 들어가는 트래픽을 차단하는 해결책이 필요함. 이를 위해 캐시 클러스터가 제공해주는 Topology 리프레쉬 뿐만 아니라 TCP 연결 응답속도 Check !

일반적으로 캐시 레이어의 응답속도는 ms 정도이기에 1초동안 응답이 오지 않는 connection은 문제가 있는 것으로 판단하고 자동으로 close하도록 설정. (즉, TCP 연결이 즉각적으로 빠르게 수행되지 않으면 빠르게 해당 연결 줄을 Close시켜 트래픽이 다운된 노드로 들어오는것을 원천 차단함.)

이로 인해 실패한 노드들을 빨리 색출할 수 이었고 안정성이 높아짐.

추가적으로, 높은 트래픽은 다운된 노드가 캐시 클러스터로 다시 진입하는 recovery과정에도 문제를 발생시켰는데, 다운된 노드는 보통 다시 뜨기 위해 Full Sync 과정을 거쳐서 클러스터로 들어오게 된다.

이때 클러스터 마스터 노드는 Full Sync 과정중에 들어오는 Write Command 들을 Buffer에 저장하는데 캐시로 들어오는 높은 트래픽은 버퍼보다 더 많은 Write Command를 발생시켜 Full Sync를 실패하도록 한다.

따라서,full sync 과정동안 Write command 수와 사이즈를 예상하여 적정한 buffer사이즈를 찾고, 예측지에 따라 버퍼 사이즈를 할당하고 여러번 테스트 했지만 쉽게 해결되지 않음.

그러던 중, 풀싱크 과정에서 예상된 write 수행보다 더 많은 write 연산 수행이 발생한다는 것을 발견함.

예상보다 많은 write은 풀싱크 과정에서 새로 뜬 replica들이 empty data set으로 데이터를 서빙하는 것이 문제가 된다.

이 현상이 캐시 클러스터에 데이터가 없다고 인식시켜 write command를 급격하게 증가시킨다.

#### 이 부분의 순환고리를 끊기 위해 replica의 데이터 사이즈나 상태정보를 이용하여 정상적으로 서빙할 수 있는 replica가 아니면 애초에 트래픽 유입을 차단시켰다.

이를 통해 급격한 write command 증가를 제거하고 full sync 실패 과정을 해결하였다.

마지막으로, 캐시 클러스터에 노드 수가 많다보니 각 노드별로 수용하는 트래픽이 불균형을 이룸.

노드 별 처리량 데이터가 5-10배 내지 차이가 나는 경우도 있고 트래픽 차이가 발생하는 만큼 CPU 사용률도 노드별로 제각각.

이러한 문제로 인해 캐시 클러스터의 크기를 정해야 하는 경우 트래픽을 가장 많이 수용하는 노드를 기준으로 CPU를 할당해야 했으며 그럼으로 인해 불필요하게 CPU가 과할당된 노드가 존재하게됨.

이러한 불균형의 원인은 캐시 클라이언트로 인한 것인데 기존 캐시 클라이언트에서는 최초 연결 시 각 샤드 별 가장 빠르게 응답하는 노드를 선택하고 통신하는 형식.

그래서 균형점을 찾기 위해 커넥션 모드를 조종해 최초 커넥션시 연결되는 고정된 노드가 아닌 매 요청 요청 마다 "랜덤"으로 가장 빠른 노드를 선텍하게함 (분산처리 수행)

해당 영상을 시청하면서 단계 별로 닥친 어려움, 회사 내에서 어떠한 아키텍처를 도입하게 됬는지에 대한 여정으로서의 소개가 인상깊었습니다. 또하 수많은 도메인들을 커먼 서빙 레이어를 구축해 중앙 집중형 방식으로 데이터를 전달하고 특히, 캐시 레이어와 리얼 타임 캐시 레이어의 데이터 활용도가 전체 데이터의 95프로라는 것은 실히 놀라웠습니다. 추가적으로 이러한 캐시 활용법에 대해서 대용량 데이터 처리에서 어떻게 효율적으로 처리해야 하는지에 대한 운영방식을 좀 더 공부해야겠다 라는 느낌을 지울 수 없었습니다. 마지막으로 클러스터 내 노드 관리, 네트워크 등 시스템 컴포넌트들간의 얼키설키 연결된 아키텍처에 대한 공부 역시 꼭 해봐야 겠습니다.

### Thank you, 쿠팡 !
