# 9장 웹 크롤러 설계

## 웹 크롤러란?

로봇 또는 스파이더라고도 부른다.

검색 엔진에서 널리 쓰는 기술로, 웹에 새로 올라오거나 갱신된 콘텐츠를 찾아내는 것이 주된 목적이다.

웹 크롤러는 몇 개 웹 페이지에서 시작해 그 링크를 따라 나가면서 새로운 콘텐츠를 수집한다.

### 사용 목적

- 검색 엔진 인덱싱 (search engine indexing) ← 가장 보편적
    
    웹 페이지를 모아 검색 엔진을 위한 로컬 인덱스를 만든다.
    
    ex. Googlebot은 구글 검색 엔진이 사용하는 웹 크롤러이다.
    
- 웹 아카이빙 (web archiving)
    
    나중에 사용할 목적으로 장기보관하기 위해 웹에서 정보를 모은다.
    
    ex. 미국 국회 도서관, EU 웹 아카이브
    
- 웹 마이닝 (web mining)
    
    인터넷에서 유용한 지식을 도출해 낸다.
    
    ex. 유명 금융 기업들은 크롤러를 사용해 주주 총회 자료나 연차 보고서 등을 다운받아 기업의 핵심 사업 방향을 알아내기도 한다.
    
- 웹 모니터링 (web monitoring)
    
    인터넷에서 저작권이나 상표권이 침해되는 사례를 모니터링할 수 있다. 
    
    ex. 디지마크
    

## 웹 크롤러 설계

가장 보편적인 검색 엔진 인덱싱을 목적으로 한 웹 크롤러 설계를 진행해보자.

### 계략적 설계안

1. 시작 URL들을 미수집 URL 저장소에 저장한다.
    - 시작 URL 집합은 웹 크롤러가 크롤링을 시작하는 출발점이다.
    - 미수집 URL 저장소는 다운로드할 URL을 저장 관리하는 FIFO 큐이다.
2. HTML 다운로더는 미수집 URL 저장소에서 URL 목록을 가져온다.
3. HTML 다운로더는 도메인 이름 변환기를 사용해 URL의 IP주소를 알아내고, 해당 IP주소로 접속하여 엡 페이지를 다운받는다.
4. 콘텐츠 파서는 다운된 HTML 페이지를 파싱하여 올바른 형식을 갖춘 페이지인지 검증한다.
5. 콘텐츠 파싱과 검증이 끝나면 중복 콘텐츠인지 확인하는 절차를 개시한다.
6. 중복 콘텐츠인지 확인하기 위해서, 해당 페이지가 이미 저장소에 있는지 본다. 
    - 중복 콘텐츠인지 확인하기 위해 웹 페이지의 해시 값을 비교한다.
    1. 이미 저장소에 있는 콘텐츠인 경우, 처리하지 않고 버린다.
    2. 저장소에 없는 콘텐츠인 경우, 저장소에 저장한 뒤 URL 추출기로 전달한다.
7. URL 추출기는 해당 HTML 페이지에서 링크를 골라낸다.
    - 링크를 추출하는 과정에서 상대 경로는 전부 절대 경로로 변환한다.
8. 골라낸 링크를 URL 필터로 전달한다.
    - URL 필터는 특정한 콘텐츠 타입이나 파일 확장자를 갖는 URL, 접속 시 오류가 발생하는 URL, 접근 제외 목록에 포함된 URL 등을 크롤링 대상에서 배제한다.
9. 필터링이 끝나고 남은 URL만 중복 URL 판별 단계로 전달한다.
10. 이미 처리한 URL인지 확인하기 위해, URL 저장소에 보관된 URL인지 살핀다.
    - 보통 블룸 필터나 해시 테이블을 사용해 이미 방문한 적이 있는 URL인지 추적한다.
    1. 이미 저장소에 있는 URL은 버린다.
11. 저장소에 없는 URL은 URL 저장소에 저장할 뿐 아니라 미수집 URL 저장소에도 전달한다.

### 상세 설계

- **DFS vs BFS?**
    
    웹은 유향 그래프와 같다. 따라서, 크롤링 프로세스는 이 유향 그래프를 에지를 따라 탐색하는 과정이다. 그래프 탐색에는 DFS와 BFS가 널리 사용되는데, DFS는 그래프 크기가 클 경우 너무 깊숙이 탐색할 우려가 있기 때문에 웹 크롤러는 보통 BFS를 사용한다. 
    
    하지만 BFS에도 두 가지 문제점이 있다.
    
    1. ‘예의 없는’ 크롤러
        
        한 페이지에서 추출한 링크는 상당수가 내부 링크, 즉 동일 서버의 다른 페이지를 참조한다. 이때 링크들을 병렬로 처리하게 되면 해당 서버에 과도한 요청으로 부하가 걸릴 수 있다. (DoS)
        
    2. URL 우선순위
        
        표준 BFS 알고리즘은 URL 간에 우선순위를 두지 않는다. 하지만 모든 웹 페이지가 같은 수준의 품질, 같은 수준의 중요성을 갖지는 않는다. 따라서 여러 가지 척도에 비추어 처리 우선순위를 구별하는 것이 필요하다.
        
- **미수집 URL 저장소**
    
    미수집 URL 저장소를 활용하면 위 BFS의 두 가지 문제점을 해결할 수 있다.
    
    1. 예의
        
        동일 웹 사이트에 대해 한 번에 한 페이지만 요청하도록 한다.
        
        다운로드를 수행하는 작업 스레드를 여러 개로 나누어, 각 스레드가 별도의 FIFO큐를 소유하게 해 해당 큐에서 꺼낸 URL만 다운로드하도록 한다. 여기서 웹 사이트의 호스트명과 FIFO큐의 매핑 테이블을 두어, 같은 호스트에 속한 URL이 언제나 같은 큐로 가도록 보장한다.
        
    2. 우선순위
        
        페이지 랭크, 트래픽 양, 갱신 빈도 등의 다양한 척도를 사용해 URL의 우선순위를 결정한다.
        
        순위결정장치를 두어 각 URL이 우선순위에 맞게 별도의 큐에 할당되도록 한다. 우선순위가 높은 큐일수록 URL이 더 많이 꺼내진다.
        
    3. 신선도
        
        이미 다운로드한 페이지더라도 데이터의 신선함을 유지하기 위해 주기적으로 재수집할 필요가 있다. 웹 페이지의 변경 이력을 활용하거나, 우선순위를 활용해 중요한 페이지는 좀 더 자주 재수집하는 방식을 택할 수 있다.
        
    4. 지속성 저장장치
        
        검색 엔진을 위한 크롤러의 경우 처리해야 하는 URL의 수가 수억 개에 달한다. 이를 모두 메모리에 보관하는 것은 바람직하지 않으므로 대부분의 URL은 디스크에 두고, IO 비용을 줄이기 위해 메모리 버퍼에 큐를 두는 방식을 택할 수 있다.
        
- **HTML 다운로더**
    1. Robots.txt
        
        로봇 제외 프로토콜이라고 부르기도 하는 Robots.txt는 웹사이트가 크롤러와 소통하는 표준적 방법이다. 이 파일에는 크롤러가 수집해도 되는 페이지 목록이 들어있다. 따라서, 웹 사이트를 긁어 가기 전에 크롤러는 해당 파일에 나열된 규칙을 먼저 확인해야 한다.
        
    2. 성능 최적화
        - 분산 크롤링: 여러 서버에 크롤링 작업을 분산하는 방법
        - 도메인 이름 변환 결과 캐시: 도메인 이름과 IP주소 사이의 관계를 캐시하는 방법
        - 지역성: 크롤링 작업을 수행하는 서버를 크롤링 대상과 가깝게 지역별로 분산하는 방법
        - 짧은 타임아웃: 최대 대기 시간을 짧게 설정하는 방법
    3. 안정성
        - 안정 해시: 다운로더 서버들에 부하를 분산할 때 적용할 수 있다.
        - 크롤링 상태 및 수집 데이터 저장: 장애가 발생한 경우에도 쉽게 복구할 수 있게 한다.
        - 예외 처리: 예외가 발생해도 전체 시스템이 중단되지 않도록 한다.
        - 데이터 검증: 시스템 오류를 방지하기 위한 수단이다.
    4. 확장성
        - 새로운 모듈을 끼워 넣음으로써 새로운 형태의 콘텐츠를 지원할 수 있도록 설계해야 한다.
    5. 문제 있는 콘텐츠 감시 및 회피
        - 중복 콘텐츠: 해시나 체크섬을 사용하면 보다 쉽게 탐지할 수 있다.
        - 거미 덫: 크롤러를 무한 루프에 빠뜨리도록 설계한 웹 페이지를 회피해야 한다.
        - 데이터 노이즈: 광고나 스크립트 코드, 스팸 URL과 같은 무가치한 콘텐츠를 제외해야 한다.
- **추가 고려 사항**
    1. 서버 측 렌더링
        
        많은 웹사이트가 JS, AJAX 등의 기술을 사용해 링크를 동적으로 생성한다. 따라서 이러한 링크를 발견하기 위해서 페이지를 파싱하기 전에 서버 측 렌더링을 적용할 수 있다.
        
    2. 원치 않는 페이지 필터링
        
        스팸 방지 컴포넌트를 두어 품질이 조악하거나 스팸성인 페이지를 걸러내도록 할 수 있다.
        
    3. 수평적 규모 확장성
        
        대규모 크롤링을 위해 서버를 무상태로 만들어 수평적 규모 확장성을 달성한다.
        
    4. 가용성, 일관성, 안정성
    5. 데이터 분석 솔루션
